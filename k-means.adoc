image::https://github.com/ahmeterdem9603/k-means_kumeleme/blob/master/Untitled.png[R]

== Kümeleme Nedir ? +
K-Means kümeleme mantığını kavrayabilmemiz için öncelikle kümelemenin tanımını yapmamız gerekir. +
Kümeleme analizi, bir veri kümesindeki bilgileri belirli yakınlık kriterlerine göre gruplara ayırma işlemidir. 
Bu grupların her birine *küme* denir. *Kümeleme* ise en basit tanımıyla
benzer özellik gösteren veri elemanlarının kendi aralarında gruplara ayrılmasıdır. +

image::https://github.com/ahmeterdem9603/k-means_kumeleme/blob/master/ikili11.png[R]

Aynı küme içindeki elemanların benzerliği fazla, kümeler arası benzerlik ise az olmalıdır. Bu tanımlara göre her küme temsil ettiği nesneleri en iyi ifade edecek şekilde düzenlenir. +

Burada temel amaç , yeni gelecek ve henüz hangi sınıfta olduğu bilinmeyen verilerin var olan sınıflardan en uygun olanına yerleştirilmesidir. Gözetimsiz sınıflamada ise amaç, başlangıçta verilen ve henüz sınıflandırılmamış bir kümede veriyi anlamlı alt kümeler oluşturacak şekilde öbeklemektir. +

image::https://github.com/ahmeterdem9603/k-means_kumeleme/blob/master/nww.PNG[R]

Kümeleme analizi istatistik, biyoloji, uzaysal veri madenciliği ve makine öğrenmesi, örüntü tanıma ve resim tanıma alanlarında kullanılmaktadır. İstatistik dünyasında k-means ve k-medoids kümeleme yöntemlerini kullanan S-Plus, SPSS ve SAS gibi paket programlar yoğunlukla kullanılmaktadır. Biyolojide genetik yapıların sınıflandırılması ve yeni yapıların keşfinde, uzaysal/düzlemsel veri madenciliğinde coğrafi konuma göre yerleşim yerlerine götürülecek mal ve hizmetler için ideal yer belirlemede, yapay zekâ alanında makine öğrenmesi için gözetimsiz öğrenme metodu olarak kullanılmaktadır. +

== Kümeleme Yöntemleri +
Kümeleme yöntemleri *hiyerarşik* ve *hiyerarşik olmayan (bölümlemeli)* kümeleme yöntemleri olarak iki ana bölümde incelenir.
K-Means kümeleme algoritması hiyerarşik olmayan bir yapıya sahiptir. Kümeleme yöntemlerinin ağaç diyagramı şu şekildedir ; +

image::https://github.com/ahmeterdem9603/k-means_kumeleme/blob/master/Capture.PNG[R]

== K-Means Kümeleme Algoritması +

En eski kümeleme yöntemlerinden biri olan k-means 1957 yılında ilk kez Hugo Steinhaus’un öne sürdüğü bir fikir olmasına rağmen 1967 yılında J.B. MacQueen tarafından geliştirilmiştir. K-means algoritmasının genel mantığı n adet veri nesnesinden oluşan bir veri setini, giriş parametresi olarak verilen k adet kümeye bölümlemektir. Amaç, gerçekleştirilen bölümleme işlemi sonunda elde edilen kümelerin, küme içi benzerliklerinin maksimum ve kümeler arası benzerliklerinin minimum olmasını sağlamaktır. Küme benzerliği, kümenin ağırlık merkezi olarak kabul edilen bir nesne ile kümedeki diğer nesneler arasındaki uzaklıkların ortalama değeri ile ölçülmektedir. +

Algoritmaya k-means adı verilmesinin nedeni, algoritmanın çalışmasından önce sabit bir küme sayısına 
ihtiyaç duyulmasıdır. Küme sayısı *'k'* ile gösterilir ve elemanlarının birbirlerine olan yakınlıklarına 
göre oluşacak grup sayısını ifade eder. Buna göre 'k' önceden bilinen ve kümeleme işlemi bitene kadar 
değeri değişmeyen sabit bir pozitif tam sayıdır. +

*K-Means Algoritmasının Matematiği* +
K-Means algoritmasında verilerin merkeze olan uzaklıklarının hesaplanmasında *öklid uzaklık formülü* temel alınmıştır. 
Dolayısıyla öklid (euclidean) uzaklığı hakkında bazı temel bilgiler şu şekildedir ; +

*Öklid Uzaklığı* +
Öklid uzaklık formülleri standartlaştırılmış verilerle değil, işlenmemiş verilerle hesaplama yapar. Öklid uzaklıkları kümeleme analizine sıra dışı olabilecek yeni nesnelerin eklenmesinden etkilenmezler. Ancak boyutlar arasındaki ölçek farklılıkları Öklid uzaklıklarını önemli ölçüde etkilemektedir. Öklid uzaklık formülü en yaygın olarak kullanılan uzaklık hesaplama formülüdür. +

Öklid uzaklık ölçüsü kullanılarak iki birim arasındaki uzaklık n birim sayısı ve p değişken sayısı olmak üzere; i,j = 1,2,3……n , i. ve j. birimin birbirine olan uzaklığı +

image::https://github.com/ahmeterdem9603/k-means_kumeleme/blob/master/ffff.PNG[R]

*K-Means Algoritmasının İşlem Basamakları* +

image::https://github.com/ahmeterdem9603/k-means_kumeleme/blob/master/ad%C4%B1mlar12.PNG[R]
image::https://github.com/ahmeterdem9603/k-means_kumeleme/blob/master/ad%C4%B1mlar34.PNG[R]

*NOT* Kümelerin kararlı yapıya geçmesinde birkaç yaklaşım söz konusudur. Bunlardan biri, hesaplanan merkezlerin koordinatlarının bir sonraki döngüde hesaplanan merkezlerin koordinatlarıyla eşit olmasıdır. Aşağıda paylaştığımız algoritma ve kod örneğinde de bu yaklaşım kullanılmıştır. +
Fakat bu yaklaşımda farklı iki nokta çiftlerinin de aynı merkezi verebilme ihtimali göz ardı edilmemelidir. +
Diğer bir yaklaşım ise, belirli adımlar sonucu oluşan kümelerdeki elemanların, bir sonraki döngü sonucunda oluşan kümelerdeki elemanlarla aynı kümelerde bulunmasıdır. Bu yaklaşım diğer yaklaşıma göre daha az hata payına sahiptir. +

*K-Means Akış Diyagramı* +

image::https://github.com/ahmeterdem9603/k-means_kumeleme/blob/master/aksddf.PNG[R]

*Phyton dilinde K-Means Algoritmasının Kodu* +

[source,python]
-----------------------------------------

import math

inputvalue = []
class1 = []
class2 = []
class3 = []
center1 = [5.5, 2.6, 4.4, 1.2]
center2 = [5.8, 2.7, 5.1, 1.9]
center3 = [7.2, 3.2, 6.0, 1.8]
iteration = 100


def isfloat(v):
    try:
        float(v)
        return True
    except:
        return False


def distance(centersw,centersl,centerpw,centerpl,value1,value2,value3,value4):
    return math.sqrt((centersw-value1)**2 + (centersl-value2)**2 + (centerpw-value3)**2 + (centerpl-value4)**2)


def clustering(center1,center2,center3,value1,value2,value3,value4):
        wclass1 = distance(center1[0],center1[1],center1[2],center1[3],value1,value2,value3,value4)
        wclass2 = distance(center2[0],center2[1],center2[2],center2[3],value1,value2,value3,value4)
        wclass3 = distance(center3[0],center3[1],center3[2],center3[3],value1,value2,value3,value4)
        value = [value1,value2,value3,value4]

        if wclass1 < wclass2 and wclass1 < wclass3 :
            class1.append(value)
        elif wclass2 < wclass1 and wclass2 < wclass3 :
            class2.append(value)
        elif wclass3 < wclass2 and wclass3 < wclass1 :
            class3.append(value)



def new_center(classValue):
    x = 0.0
    y = 0.0
    z = 0.0
    t = 0.0
    for i in range(len(classValue)):
        x += classValue[i][0]
        y += classValue[i][1]
        z += classValue[i][2]
        t += classValue[i][3]
    return [x / len(classValue), y / len(classValue), z / len(classValue), t / len(classValue)]

with open('iris_data.txt') as openfile:
    for line in openfile:
        line_ = line.split(",")
        line2 = []
        for k in line_:
            if not isfloat(k):
                pass
            else:
                line2.append(float(k))
        inputvalue.append(line2)


for i in range(iteration):
    backup_center1 = center1
    backup_center2 = center2
    backup_center3 = center3
    for i in range(0,len(inputvalue),1):
        clustering(center1,center2,center3, inputvalue[i][0],inputvalue[i][1],inputvalue[i][2],inputvalue[i][3])
    center1 = new_center(class1)
    center2 = new_center(class2)
    center3 = new_center(class3)
    i1 = 0
    i2 = 0
    i3 = 0
    for n in range(3):
        count1 = 0
        count2 = 0
        count3 = 0
        for j in range(n*50,(n+1)*50,1):
            if i1 < len(class1) and class1[i1]==inputvalue[j]:
                count1 += 1
                i1 += 1
            elif i2 < len(class2) and class2[i2]==inputvalue[j]:
                count2 += 1
                i2 += 1
            elif i3 < len(class3) and class3[i3]==inputvalue[j]:
                count3 += 1
                i3 += 1
        print count1, count2, count3, j
    print "****************"
    print len(class1), len(class2), len(class3)
    print center1
    print center2
    print center3
    class1 = []
    class2 = []
    class3 = []
    if backup_center1==center1 and \
        backup_center2==center2 and \
        backup_center3==center3:
        break
    else:
        continue


-----------------------------------------

